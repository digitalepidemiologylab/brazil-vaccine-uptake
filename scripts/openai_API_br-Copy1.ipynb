{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e90b7c28",
   "metadata": {},
   "source": [
    "# Import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "433219e8-8f66-4be5-a3b8-e39fca644032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c68f056-74fe-4f29-9daf-6bdef5cc0701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get OpenAI API secret key\n",
    "open_ai_key = open('../data/local/openai_key.txt', 'r').read()\n",
    "openai.api_key = open_ai_key\n",
    "#openai.Model.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81541320-fa96-4a0b-b650-0173598db2e1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 422 entries, 0 to 421\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   text       422 non-null    object \n",
      " 1   negative   422 non-null    int64  \n",
      " 2   positive   422 non-null    int64  \n",
      " 3   neutral    422 non-null    int64  \n",
      " 4   total      422 non-null    int64  \n",
      " 5   neg_per    422 non-null    float64\n",
      " 6   pos_per    422 non-null    float64\n",
      " 7   neu_per    422 non-null    float64\n",
      " 8   agreement  422 non-null    int64  \n",
      "dtypes: float64(3), int64(5), object(1)\n",
      "memory usage: 29.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Get annotated tweets\n",
    "with open('../data/local/paho_tweets_filtered.csv', 'rb') as f:\n",
    "    result = chardet.detect(f.read())  # or readline if the file is large\n",
    "\n",
    "\n",
    "paho = pd.read_csv('../data/local/mturk_tweets_filtered.csv', encoding=result['encoding']).reset_index().iloc[:, 2:]\n",
    "\n",
    "paho.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d7e0ea",
   "metadata": {},
   "source": [
    "# Using sample to test prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00889b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for GPT\n",
    "prompt_raw_1 = \"Qual é a atitude do autor em relação às vacinas expresso pelo usuário do texto do tweet delimitado por crases triplos? \\\n",
    "Use uma das seguintes palavras: neutro, negativo, positivo. Inclua uma explicação para a seleção do sentimento. \\\n",
    "```{TEXTO_DO_TWEET_AQUI}```\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbe518e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for GPT\n",
    "prompt_raw_2 = \"Qual é a atitude do autor em relação às vacinas expresso pelo usuário do texto do tweet delimitado por crases triplos? \\\n",
    "Use uma das seguintes palavras: neutro, negativo, positivo. Inclua uma explicação para a seleção do sentimento. \\\n",
    "\\\n",
    "Exemplos de sentimento positivo: \\\n",
    "* Por favor não se esqueçam de tomar a vacina! \\\n",
    "* Vacina contra o câncer da pele é testada com sucesso. \\\n",
    "\\\n",
    "Examplos de sentimento neutro: \\\n",
    "* Fui tomar vacina ontem. \\\n",
    "* A nova campanha de vacinação contra a gripe começou hoje. \\\n",
    "\\\n",
    "Examplos de sentimento negativo: \\\n",
    "* Tomei vacina contra a gripe e meu braço ta doendo. \\\n",
    "* Estudo mostra efeitos colaterais sérios da nova vacina contra a gripe. \\\n",
    "\\\n",
    "```{TEXTO_DO_TWEET_AQUI}```\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04317462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for GPT\n",
    "prompt_raw_3 = \"Give me the sentiment regarding vaccination expressed by the user of the tweet text delimited by triple backticks. \\\n",
    "Use one of the following words: neutral, negative, positive. Include an explanation for the selection of the sentiment. \\\n",
    "```{TWEET_TEXT_HERE}```\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a315bbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paho.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c15b8328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"A #vacina contra a catapora só começou a ser usada há cerca de 15 anos, e foi somente em 2013 que o Ministério... <url>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paho.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe47a29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_gpt = []\n",
    "sent_gpt = []\n",
    "text = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f62bf0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "The model `mistral-tiny` does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m422\u001b[39m):\n\u001b[0;32m      2\u001b[0m     prompt_i \u001b[38;5;241m=\u001b[39m prompt_raw_1\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTEXTO_DO_TWEET_AQUI\u001b[39m\u001b[38;5;124m'\u001b[39m, paho\u001b[38;5;241m.\u001b[39miloc[i,\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;66;43;03m#model=\"text-davinci-003\",\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmistral-tiny\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_i\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;66;43;03m#max_tokens=256,\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     text\u001b[38;5;241m.\u001b[39mappend(paho\u001b[38;5;241m.\u001b[39miloc[i,\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     14\u001b[0m     sent_gpt\u001b[38;5;241m.\u001b[39mappend(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\openai\\api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    207\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    215\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    216\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    217\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    218\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    225\u001b[0m     )\n\u001b[1;32m--> 226\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\openai\\api_requestor.py:619\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    612\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    613\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    614\u001b[0m         )\n\u001b[0;32m    615\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    616\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 619\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    625\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    626\u001b[0m     )\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\openai\\api_requestor.py:682\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    680\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    683\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: The model `mistral-tiny` does not exist"
     ]
    }
   ],
   "source": [
    "for i in range(0, 422):\n",
    "    prompt_i = prompt_raw_1.replace('TEXTO_DO_TWEET_AQUI', paho.iloc[i,0])\n",
    "    response = openai.ChatCompletion.create(\n",
    "      #model=\"text-davinci-003\",\n",
    "      model = \"mistral-tiny\",\n",
    "      #messages=[{\"role\": \"user\", \"content\": prompt_i}],\n",
    "      temperature=0.8,\n",
    "      #max_tokens=256,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0\n",
    "    )\n",
    "    text.append(paho.iloc[i,0])\n",
    "    sent_gpt.append(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "52c9278a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, 422):\n",
    "    prompt_i = prompt_raw_2.replace('TEXTO_DO_TWEET_AQUI', paho.iloc[i,0])\n",
    "    response = openai.Completion.create(\n",
    "      model=\"text-davinci-003\",\n",
    "      prompt=prompt_i,\n",
    "      temperature=0.8,\n",
    "      max_tokens=256,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0\n",
    "    )\n",
    "    text.append(paho.iloc[i,0])\n",
    "    sent_gpt.append(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b80e1e4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 422 entries, 0 to 421\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   text           422 non-null    object\n",
      " 1   sentiment_gpt  422 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 6.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_gpt_total = pd.DataFrame(list(zip(text, sent_gpt)),\n",
    "                            columns = ['text', 'sentiment_gpt'])\n",
    "df_gpt_total.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f5c1cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt_total['prompt'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "965e63a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt_total['gpt'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de211f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_gpt</th>\n",
       "      <th>prompt</th>\n",
       "      <th>gpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>“Ta bonitinho @&lt;user&gt; /“Ainda da tempo pra vc ...</td>\n",
       "      <td>Apologies, but I can't assess the sentiment as...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>“tia trice pergunta: vocês tem medo de tomar v...</td>\n",
       "      <td>As an AI model, I need the tweet text to analy...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>• Santa Casa do Rio e universidade canadense v...</td>\n",
       "      <td>```Vaccines are the key to overcoming this pan...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>&lt;U+26A0&gt;&lt;U+FE0F&gt;&lt;U+26A0&gt;&lt;U+FE0F&gt;DIRETO DA REDA...</td>\n",
       "      <td>```Just got my second vaccine shot. Feeling re...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>&lt;U+0001F342&gt; quem tem alergia a clara de ovo n...</td>\n",
       "      <td>```I can't believe it's 2021 and we are still ...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "417  “Ta bonitinho @<user> /“Ainda da tempo pra vc ...   \n",
       "418  “tia trice pergunta: vocês tem medo de tomar v...   \n",
       "419  • Santa Casa do Rio e universidade canadense v...   \n",
       "420  <U+26A0><U+FE0F><U+26A0><U+FE0F>DIRETO DA REDA...   \n",
       "421  <U+0001F342> quem tem alergia a clara de ovo n...   \n",
       "\n",
       "                                         sentiment_gpt  prompt  gpt  \n",
       "417  Apologies, but I can't assess the sentiment as...       3    4  \n",
       "418  As an AI model, I need the tweet text to analy...       3    4  \n",
       "419  ```Vaccines are the key to overcoming this pan...       3    4  \n",
       "420  ```Just got my second vaccine shot. Feeling re...       3    4  \n",
       "421  ```I can't believe it's 2021 and we are still ...       3    4  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt_total.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a901463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_gpt_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c7ce791",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt_total_all = df_gpt_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f921c6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lespinosa\\AppData\\Local\\Temp\\ipykernel_26232\\964839105.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gpt_total_all = df_gpt_total_all.append(df_gpt_total)\n"
     ]
    }
   ],
   "source": [
    "df_gpt_total_all = df_gpt_total_all.append(df_gpt_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bd6677b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_gpt_total_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1eb834c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_gpt</th>\n",
       "      <th>prompt</th>\n",
       "      <th>gpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>“Ta bonitinho @&lt;user&gt; /“Ainda da tempo pra vc ...</td>\n",
       "      <td>Apologies, but I can't assess the sentiment as...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>“tia trice pergunta: vocês tem medo de tomar v...</td>\n",
       "      <td>As an AI model, I need the tweet text to analy...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>• Santa Casa do Rio e universidade canadense v...</td>\n",
       "      <td>```Vaccines are the key to overcoming this pan...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>&lt;U+26A0&gt;&lt;U+FE0F&gt;&lt;U+26A0&gt;&lt;U+FE0F&gt;DIRETO DA REDA...</td>\n",
       "      <td>```Just got my second vaccine shot. Feeling re...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>&lt;U+0001F342&gt; quem tem alergia a clara de ovo n...</td>\n",
       "      <td>```I can't believe it's 2021 and we are still ...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "417  “Ta bonitinho @<user> /“Ainda da tempo pra vc ...   \n",
       "418  “tia trice pergunta: vocês tem medo de tomar v...   \n",
       "419  • Santa Casa do Rio e universidade canadense v...   \n",
       "420  <U+26A0><U+FE0F><U+26A0><U+FE0F>DIRETO DA REDA...   \n",
       "421  <U+0001F342> quem tem alergia a clara de ovo n...   \n",
       "\n",
       "                                         sentiment_gpt  prompt  gpt  \n",
       "417  Apologies, but I can't assess the sentiment as...       3    4  \n",
       "418  As an AI model, I need the tweet text to analy...       3    4  \n",
       "419  ```Vaccines are the key to overcoming this pan...       3    4  \n",
       "420  ```Just got my second vaccine shot. Feeling re...       3    4  \n",
       "421  ```I can't believe it's 2021 and we are still ...       3    4  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt_total_all.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "420096e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt_total_all.to_csv('../data/local/gpt_sentiment_paho_prompt3_gpt4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91665254",
   "metadata": {},
   "source": [
    "# Using three categories for vaccine sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9865707-b6c8-4dcc-bf88-1736bb13310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for GPT\n",
    "prompt_raw = \"Give me the sentiment regarding vaccination expressed by the user in the tweet text delimited by triple backticks. \\\n",
    "Use one of the following words: neutral, negative, positive. \\\n",
    "```{TWEET_TEXT_HERE}```\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ce27066-8efb-4903-81ea-0d3d4b5c1e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt_i = prompt_raw.replace('TWEET_TEXT_HERE', tweets.iloc[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c026094b-57da-48e7-a465-5810644f8fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4786"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c23b36d9-0f9a-42fe-a366-8df1434a585b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of      index                                               text  neutral  \\\n",
       "0        0  \"#Shingrix Vaccine Against Shingles Remains In...        3   \n",
       "1        1  \"...French scientist Louis Pasteur coined the ...        3   \n",
       "2        2  \"...due to potentially unexplained illnesses.\"...        2   \n",
       "3        3  \"...on average, it takes 10.7 years to develop...        3   \n",
       "4        4  \"..only 29 percent of the teens its members in...        3   \n",
       "..     ...                                                ...      ...   \n",
       "96      96  #COVID19 vaccine could be delivered in mailabl...        4   \n",
       "97      97  #COVID19Vaccine in 1 month? CSIR pins hope on ...        4   \n",
       "98      98  #COVID19dz Ignorance at the utmost level as co...        1   \n",
       "99      99  #CRO Vaccine Market in Austria to 2021 Market ...        3   \n",
       "100    100  #California has just implemented one of the #s...        3   \n",
       "\n",
       "     negative  positive  total  \n",
       "0           0         0      3  \n",
       "1           0         0      3  \n",
       "2           1         7     10  \n",
       "3           0         0      3  \n",
       "4           0         0      3  \n",
       "..        ...       ...    ...  \n",
       "96          1         5     10  \n",
       "97          0         7     11  \n",
       "98          1         9     11  \n",
       "99          0         0      3  \n",
       "100         0         0      3  \n",
       "\n",
       "[101 rows x 6 columns]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tweets.iloc[:101, :]\n",
    "test.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "986b9ea8-c64d-4e27-ba53-1f57c3b53d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets1 = tweets.iloc[0:306,:]\n",
    "tweets2 = tweets.iloc[306:601,:]\n",
    "tweets3 = tweets.iloc[601:901, :]\n",
    "tweets4 = tweets.iloc[901:1201, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c487242a-2b6e-4b45-90a4-150efed6e32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"...French scientist Louis Pasteur coined the term “vaccination” in honour of Jenner’s work (vacca being the Latin for cow)\" - TIL! 🐮💉 <url>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ecfc3a3b-514a-43f9-9a1a-3506358cc2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_gpt = []\n",
    "sent_gpt = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "80ade1ff-1238-4ab3-a151-3a2df1163a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,4785):\n",
    "    prompt_i = prompt_raw.replace('TWEET_TEXT_HERE', tweets.iloc[i,1])\n",
    "    response = openai.Completion.create(\n",
    "      model=\"text-davinci-003\",\n",
    "      prompt=prompt_i,\n",
    "      temperature=0.8,\n",
    "      max_tokens=256,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0\n",
    "    )\n",
    "    id_gpt.append(tweets.iloc[i,0])\n",
    "    sent_gpt.append(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c9a278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a251c314-a165-4a19-8bc0-06f04c2d7feb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4785 entries, 0 to 4784\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   id_gpt         4785 non-null   int64 \n",
      " 1   sentiment_gpt  4785 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 74.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_gpt_total = pd.DataFrame(list(zip(id_gpt, sent_gpt)),\n",
    "                            columns = ['id_gpt', 'sentiment_gpt'])\n",
    "df_gpt_total.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ef24fe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt_total['run'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9386b878-5de3-49d7-b055-a88cea4c6d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_gpt</th>\n",
       "      <th>sentiment_gpt</th>\n",
       "      <th>run</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4780</th>\n",
       "      <td>4780</td>\n",
       "      <td>\\n\\nNegative</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4781</th>\n",
       "      <td>4781</td>\n",
       "      <td>\\n\\npositive</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4782</th>\n",
       "      <td>4782</td>\n",
       "      <td>\\n\\nneutral</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4783</th>\n",
       "      <td>4783</td>\n",
       "      <td>\\n\\npositive</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4784</th>\n",
       "      <td>4784</td>\n",
       "      <td>\\n\\nNeutral</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_gpt sentiment_gpt  run\n",
       "4780    4780  \\n\\nNegative    3\n",
       "4781    4781  \\n\\npositive    3\n",
       "4782    4782   \\n\\nneutral    3\n",
       "4783    4783  \\n\\npositive    3\n",
       "4784    4784   \\n\\nNeutral    3"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt_total.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d7b69a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lespinosa\\AppData\\Local\\Temp\\ipykernel_23560\\3678373193.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gpt_total_all = df_gpt_total.append(df_gpt_total2)\n"
     ]
    }
   ],
   "source": [
    "#df_gpt_total_all = df_gpt_total.append(df_gpt_total2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ba4e26f3-b7f2-4813-b50a-cb7905e0abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt_total.to_excel('../data/local/gpt_sentiment_mturk_v4.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f618d0e5",
   "metadata": {},
   "source": [
    "# Using two categories for vaccine sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae054d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1235574994924490752</td>\n",
       "      <td>@user @user I saw #VaxxedII yesterday and I ha...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>1236451808412909568</td>\n",
       "      <td>Dear anti-vaxxers. If you are legitimately wor...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>1237492335430250496</td>\n",
       "      <td>@user @user thank you for the vaccine LOL #Wel...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>1237894709306986496</td>\n",
       "      <td>Remember polio? Killed a lot of people. Vaccin...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>1239077015250030592</td>\n",
       "      <td>You be ready to pay what this Coronavirus vacc...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                   id  \\\n",
       "18     18  1235574994924490752   \n",
       "22     22  1236451808412909568   \n",
       "26     26  1237492335430250496   \n",
       "28     28  1237894709306986496   \n",
       "38     38  1239077015250030592   \n",
       "\n",
       "                                                 text label_tag  \n",
       "18  @user @user I saw #VaxxedII yesterday and I ha...  negative  \n",
       "22  Dear anti-vaxxers. If you are legitimately wor...  positive  \n",
       "26  @user @user thank you for the vaccine LOL #Wel...  positive  \n",
       "28  Remember polio? Killed a lot of people. Vaccin...  positive  \n",
       "38  You be ready to pay what this Coronavirus vacc...  negative  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_pos_neg = tweets[tweets['label_tag'].isin(['positive', 'negative'])]\n",
    "tweets_pos_neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "00b76182-73e4-45c0-aa71-efa35591b01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1008751928568840192</td>\n",
       "      <td>Great news to see. Hopefully, folks who disput...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1008751948957351936</td>\n",
       "      <td>The global community must invest in further re...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1008752099222523904</td>\n",
       "      <td>HPV vaccine has almost wiped out infections in...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1010156916553736192</td>\n",
       "      <td>So I can catch this shit too and need treatmen...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1010157450618601472</td>\n",
       "      <td>Could a #vaccine for #type-1 diabetes be on th...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                   id  \\\n",
       "1      1  1008751928568840192   \n",
       "2      2  1008751948957351936   \n",
       "3      3  1008752099222523904   \n",
       "4      4  1010156916553736192   \n",
       "5      5  1010157450618601472   \n",
       "\n",
       "                                                text label_tag  \n",
       "1  Great news to see. Hopefully, folks who disput...  positive  \n",
       "2  The global community must invest in further re...  positive  \n",
       "3  HPV vaccine has almost wiped out infections in...  positive  \n",
       "4  So I can catch this shit too and need treatmen...  negative  \n",
       "5  Could a #vaccine for #type-1 diabetes be on th...  positive  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_new_pos_neg = tweets_new[tweets_new['label_tag'].isin(['positive', 'negative'])]\n",
    "tweets_new_pos_neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14e6c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_raw_pos_neg = \"Please give me the sentiment regarding vaccination in the following tweet: \\\n",
    "\"TWEET_TEXT_HERE\\\"\\nUse one of the following words: negative, positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b15c9420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_new_pos_neg.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f726abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1235574994924490752</td>\n",
       "      <td>@user @user I saw #VaxxedII yesterday and I ha...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>1236451808412909568</td>\n",
       "      <td>Dear anti-vaxxers. If you are legitimately wor...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                   id  \\\n",
       "18     18  1235574994924490752   \n",
       "22     22  1236451808412909568   \n",
       "\n",
       "                                                 text label_tag  \n",
       "18  @user @user I saw #VaxxedII yesterday and I ha...  negative  \n",
       "22  Dear anti-vaxxers. If you are legitimately wor...  positive  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tweets_pos_neg.iloc[0:2, :]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bcdc70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_pos_neg1 = tweets_pos_neg.iloc[0:306,:]\n",
    "tweets_pos_neg2 = tweets_pos_neg.iloc[306:601,:]\n",
    "tweets_pos_neg3 = tweets_pos_neg.iloc[601:901, :]\n",
    "tweets_pos_neg4 = tweets_pos_neg.iloc[901:1201, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cfa78bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_pos_neg4 = tweets_pos_neg.iloc[901:1201, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80b65b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_gpt_two = []\n",
    "sent_gpt_two = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48395218",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,128):\n",
    "    prompt_two_i = prompt_raw_pos_neg.replace('TWEET_TEXT_HERE', tweets_new_pos_neg.iloc[i,2])\n",
    "    response_two = openai.Completion.create(\n",
    "      model=\"text-davinci-003\",\n",
    "      prompt=prompt_two_i,\n",
    "      temperature=0.7,\n",
    "      max_tokens=256,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0\n",
    "    )\n",
    "    id_gpt_two.append(tweets_new_pos_neg.iloc[i,0])\n",
    "    sent_gpt_two.append(response_two.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69cfbfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_two_1339 = prompt_raw_pos_neg.replace('TWEET_TEXT_HERE', tweets_pos_neg.iloc[1339,2])\n",
    "response_two = openai.Completion.create(\n",
    "      model=\"text-davinci-003\",\n",
    "      prompt=prompt_two_1339,\n",
    "      temperature=0.7,\n",
    "      max_tokens=256,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0\n",
    "    )\n",
    "id_gpt_two.append(tweets_pos_neg.iloc[1339,0])\n",
    "sent_gpt_two.append(response_two.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bcee3e9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 128 entries, 0 to 127\n",
      "Data columns (total 2 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   id_gpt_two         128 non-null    int64 \n",
      " 1   sentiment_gpt_two  128 non-null    object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_two_gpt_total = pd.DataFrame(list(zip(id_gpt_two, sent_gpt_two)),\n",
    "                            columns = ['id_gpt_two', 'sentiment_gpt_two'])\n",
    "df_two_gpt_total.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c0dd6a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_gpt_two</th>\n",
       "      <th>sentiment_gpt_two</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>179</td>\n",
       "      <td>, or neutral\\n\\nPositive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>180</td>\n",
       "      <td>, or neutral\\n\\nPositive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>181</td>\n",
       "      <td>, or neutral\\n\\nNegative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>182</td>\n",
       "      <td>, or neutral\\n\\nPositive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>184</td>\n",
       "      <td>\\n\\nNegative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_gpt_two         sentiment_gpt_two\n",
       "123         179  , or neutral\\n\\nPositive\n",
       "124         180  , or neutral\\n\\nPositive\n",
       "125         181  , or neutral\\n\\nNegative\n",
       "126         182  , or neutral\\n\\nPositive\n",
       "127         184              \\n\\nNegative"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_two_gpt_total.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "304fbd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_gpt13 = id_gpt\n",
    "sent_gpt13 = sent_gpt\n",
    "df_gpt_total13 = df_gpt_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73353eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "#df_gpt_total1.to_csv('../data/local/gpt_sentiment1.csv')\n",
    "df_gpt_total1['sentiment_gpt2'] = df_gpt_total1['sentiment_gpt'].to_string()\n",
    "print(type(df_gpt_total1['sentiment_gpt2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c8d28fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sent_gpt1.to_csv('../data/local/gpt_sentiment1_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3eda4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_two_gpt_total.to_excel('../data/local/gpt_sentiment_new_pos_neg.xlsx')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
