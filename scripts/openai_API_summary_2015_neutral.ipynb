{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e90b7c28",
   "metadata": {},
   "source": [
    "# Import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "433219e8-8f66-4be5-a3b8-e39fca644032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2c68f056-74fe-4f29-9daf-6bdef5cc0701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get OpenAI API secret key (change this file with your own OpenAI key)\n",
    "open_ai_key = open('../data/local/openai_key.txt', 'r').read()\n",
    "openai.api_key = open_ai_key\n",
    "#openai.Model.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "aa3d0327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for GPT\n",
    "prompt_raw = \"I would like to summarise in maximum 300 characters and in English what the following sentences in Portuguese talk about. \\\n",
    "Do not use aspects mentioned only in one sentence as part of the summary: TWEETS\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7787f4",
   "metadata": {},
   "source": [
    "# 2015 neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a04f7fe",
   "metadata": {},
   "source": [
    "## January"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6663b9cf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1482 entries, 0 to 1481\n",
      "Data columns (total 53 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   index                   1482 non-null   int64  \n",
      " 1   LocationCode            1482 non-null   object \n",
      " 2   LocationName            1482 non-null   object \n",
      " 3   StatesCode              1482 non-null   object \n",
      " 4   ...4                    1482 non-null   int64  \n",
      " 5   id                      1482 non-null   float64\n",
      " 6   text                    1482 non-null   object \n",
      " 7   label                   1482 non-null   object \n",
      " 8   in_reply_to_status_id   168 non-null    float64\n",
      " 9   in_reply_to_user_id     174 non-null    float64\n",
      " 10  quoted_user_id          0 non-null      float64\n",
      " 11  quoted_status_id        0 non-null      float64\n",
      " 12  retweeted_user_id       284 non-null    float64\n",
      " 13  retweeted_status_id     284 non-null    float64\n",
      " 14  created_at              1482 non-null   object \n",
      " 15  entities.user_mentions  545 non-null    object \n",
      " 16  user.id                 1482 non-null   int64  \n",
      " 17  user.screen_name        1482 non-null   object \n",
      " 18  user.name               1482 non-null   object \n",
      " 19  user.description        1266 non-null   object \n",
      " 20  user.timezone           0 non-null      float64\n",
      " 21  user.location           1461 non-null   object \n",
      " 22  user.num_followers      1482 non-null   int64  \n",
      " 23  user.num_following      1482 non-null   int64  \n",
      " 24  user.created_at         1482 non-null   object \n",
      " 25  user.statuses_count     1482 non-null   int64  \n",
      " 26  user.is_verified        1482 non-null   bool   \n",
      " 27  lang                    1482 non-null   object \n",
      " 28  token_count             1482 non-null   int64  \n",
      " 29  is_retweet              1482 non-null   bool   \n",
      " 30  has_quote               1482 non-null   bool   \n",
      " 31  is_reply                1482 non-null   bool   \n",
      " 32  contains_keywords       1482 non-null   bool   \n",
      " 33  longitude               1482 non-null   float64\n",
      " 34  latitude                1482 non-null   float64\n",
      " 35  country_code            1482 non-null   object \n",
      " 36  geoname_id              1397 non-null   float64\n",
      " 37  location_type           1482 non-null   object \n",
      " 38  geo_type                1482 non-null   int64  \n",
      " 39  region                  1482 non-null   object \n",
      " 40  subregion               1482 non-null   object \n",
      " 41  num_quotes              1482 non-null   int64  \n",
      " 42  num_replies             1482 non-null   int64  \n",
      " 43  num_retweets            1482 non-null   int64  \n",
      " 44  sent_gpt                1482 non-null   object \n",
      " 45  gpt_sent_presence       1482 non-null   int64  \n",
      " 46  cleaned_text_lem        1482 non-null   object \n",
      " 47  cleaned_text            1482 non-null   object \n",
      " 48  month                   1482 non-null   int64  \n",
      " 49  year                    1482 non-null   int64  \n",
      " 50  week                    1482 non-null   int64  \n",
      " 51  year_month              1482 non-null   object \n",
      " 52  year_week               1482 non-null   object \n",
      "dtypes: bool(5), float64(11), int64(15), object(22)\n",
      "memory usage: 563.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Get monthly data\n",
    "df_2015_01_neu = pd.read_csv('../data/local/df_neu_2015-01.csv').reset_index()\n",
    "df_2015_01_neu.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f621ec",
   "metadata": {},
   "source": [
    "### Representative sample based on week and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "921a735a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_week</th>\n",
       "      <th>LocationName</th>\n",
       "      <th>group_size</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-w01</td>\n",
       "      <td>Acre</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-w01</td>\n",
       "      <td>Alagoas</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-w01</td>\n",
       "      <td>Amapa</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-w01</td>\n",
       "      <td>Amazonas</td>\n",
       "      <td>8</td>\n",
       "      <td>0.005398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-w01</td>\n",
       "      <td>Bahia</td>\n",
       "      <td>14</td>\n",
       "      <td>0.009447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2015-w05</td>\n",
       "      <td>Rio Grande Do Sul</td>\n",
       "      <td>13</td>\n",
       "      <td>0.008772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2015-w05</td>\n",
       "      <td>Rondonia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2015-w05</td>\n",
       "      <td>Santa Catarina</td>\n",
       "      <td>6</td>\n",
       "      <td>0.004049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2015-w05</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>32</td>\n",
       "      <td>0.021592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2015-w05</td>\n",
       "      <td>Sergipe</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    year_week       LocationName  group_size  proportion\n",
       "0    2015-w01               Acre           1    0.000675\n",
       "1    2015-w01            Alagoas           4    0.002699\n",
       "2    2015-w01              Amapa           4    0.002699\n",
       "3    2015-w01           Amazonas           8    0.005398\n",
       "4    2015-w01              Bahia          14    0.009447\n",
       "..        ...                ...         ...         ...\n",
       "100  2015-w05  Rio Grande Do Sul          13    0.008772\n",
       "101  2015-w05           Rondonia           1    0.000675\n",
       "102  2015-w05     Santa Catarina           6    0.004049\n",
       "103  2015-w05          Sao Paulo          32    0.021592\n",
       "104  2015-w05            Sergipe           5    0.003374\n",
       "\n",
       "[105 rows x 4 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Calculate the size of each group (year_week, LocationName)\n",
    "group_sizes = df_2015_01_neu.groupby(['year_week', 'LocationName']).size().reset_index(name='group_size')\n",
    "\n",
    "# Step 2: Calculate the proportion of each group in the dataset\n",
    "total_rows = len(df_2015_01_neu)\n",
    "group_sizes['proportion'] = group_sizes['group_size'] / total_rows\n",
    "group_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "89b38fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_week</th>\n",
       "      <th>LocationName</th>\n",
       "      <th>group_size</th>\n",
       "      <th>proportion</th>\n",
       "      <th>sample_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-w01</td>\n",
       "      <td>Acre</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-w01</td>\n",
       "      <td>Alagoas</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002699</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-w01</td>\n",
       "      <td>Amapa</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002699</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-w01</td>\n",
       "      <td>Amazonas</td>\n",
       "      <td>8</td>\n",
       "      <td>0.005398</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-w01</td>\n",
       "      <td>Bahia</td>\n",
       "      <td>14</td>\n",
       "      <td>0.009447</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2015-w05</td>\n",
       "      <td>Rio Grande Do Sul</td>\n",
       "      <td>13</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2015-w05</td>\n",
       "      <td>Rondonia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2015-w05</td>\n",
       "      <td>Santa Catarina</td>\n",
       "      <td>6</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2015-w05</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>32</td>\n",
       "      <td>0.021592</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2015-w05</td>\n",
       "      <td>Sergipe</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003374</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    year_week       LocationName  group_size  proportion  sample_size\n",
       "0    2015-w01               Acre           1    0.000675            1\n",
       "1    2015-w01            Alagoas           4    0.002699            6\n",
       "2    2015-w01              Amapa           4    0.002699            6\n",
       "3    2015-w01           Amazonas           8    0.005398           13\n",
       "4    2015-w01              Bahia          14    0.009447           23\n",
       "..        ...                ...         ...         ...          ...\n",
       "100  2015-w05  Rio Grande Do Sul          13    0.008772           21\n",
       "101  2015-w05           Rondonia           1    0.000675            1\n",
       "102  2015-w05     Santa Catarina           6    0.004049            9\n",
       "103  2015-w05          Sao Paulo          32    0.021592           52\n",
       "104  2015-w05            Sergipe           5    0.003374            8\n",
       "\n",
       "[105 rows x 5 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Define the target sample size\n",
    "target_sample_size = 2450\n",
    "\n",
    "# Step 4: Calculate the sample size for each group (based on its proportion)\n",
    "group_sizes['sample_size'] = np.floor(group_sizes['proportion'] * target_sample_size).astype(int)\n",
    "group_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a50fe53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Merge this sample size information back to the original DataFrame\n",
    "df_2015_01_neu_sample_size = pd.merge(df_2015_01_neu, group_sizes[['year_week', 'LocationName', 'sample_size']], \n",
    "                               on=['year_week', 'LocationName'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "85555ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 1482 rows.\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Perform the stratified sampling\n",
    "#df_2015_01_neu_sample = df_2015_01_neu_sample_size.groupby(['year_week', 'LocationName']).apply(\n",
    " #   lambda group: group.sample(n=group['sample_size'].iloc[0], random_state=42)\n",
    "#).reset_index(drop=True)\n",
    "df_2015_01_neu_sample = df_2015_01_neu\n",
    "# Step 7: Check the result\n",
    "print(f\"Sampled {len(df_2015_01_neu_sample)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0346bf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gpt_2015_01_neu = '\\n'.join(df_2015_01_neu_sample['text'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89facff",
   "metadata": {},
   "source": [
    "### Prompts and loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d131b6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = prompt_raw.replace('TWEETS', text_gpt_2015_01_neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7b46f355",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[156], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o-mini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_1\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Maximum number of tokens in the response\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Controls the randomness of the output\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\openai\\api_requestor.py:216\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    207\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    215\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 216\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_raw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupplied_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response(result, stream)\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\openai\\api_requestor.py:516\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[1;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    514\u001b[0m     _thread_context\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m _make_session()\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 516\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_thread_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mabs_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mTIMEOUT_SECS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mTimeout(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest timed out: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    700\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 489\u001b[0m         resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m            \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m            \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproxy_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[0;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    444\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\http\\client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1377\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\http\\client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\http\\client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4o-mini\",  \n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt_1}\n",
    "    ],\n",
    "    max_tokens=400,  # Maximum number of tokens in the response\n",
    "    temperature=0.7  # Controls the randomness of the output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c76466",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89927f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = []\n",
    "dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4adcee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.append(\"2015_01_neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab412b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.append(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8731c5c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_2015_neu = pd.DataFrame(list(zip(dataset, summary)),\n",
    "                            columns = ['dataset', 'summary'])\n",
    "df_2015_neu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3165ba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015_neu.tail(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2877d37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000d2343",
   "metadata": {},
   "source": [
    "## February"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad27d675",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get monthly data\n",
    "df_2015_02_neu = pd.read_csv('../data/local/df_neu_2015-02.csv').reset_index()\n",
    "df_2015_02_neu.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39b7c34",
   "metadata": {},
   "source": [
    "### Representative sample based on week and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a2f945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the size of each group (year_week, LocationName)\n",
    "group_sizes = df_2015_02_neu.groupby(['year_week', 'LocationName']).size().reset_index(name='group_size')\n",
    "\n",
    "# Step 2: Calculate the proportion of each group in the dataset\n",
    "total_rows = len(df_2015_02_neu)\n",
    "group_sizes['proportion'] = group_sizes['group_size'] / total_rows\n",
    "group_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fb67fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the target sample size\n",
    "target_sample_size = 2450\n",
    "\n",
    "# Step 4: Calculate the sample size for each group (based on its proportion)\n",
    "group_sizes['sample_size'] = np.floor(group_sizes['proportion'] * target_sample_size).astype(int)\n",
    "group_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefa193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Merge this sample size information back to the original DataFrame\n",
    "df_2015_02_neu_sample_size = pd.merge(df_2015_02_neu, group_sizes[['year_week', 'LocationName', 'sample_size']], \n",
    "                               on=['year_week', 'LocationName'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5cc94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Perform the stratified sampling\n",
    "#df_2015_02_neu_sample = df_2015_02_neu_sample_size.groupby(['year_week', 'LocationName']).apply(\n",
    " #   lambda group: group.sample(n=group['sample_size'].iloc[0], random_state=42)\n",
    "#).reset_index(drop=True)\n",
    "df_2015_02_neu_sample = df_2015_02_neu\n",
    "# Step 7: Check the result\n",
    "print(f\"Sampled {len(df_2015_02_neu_sample)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceb36c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gpt_2015_02_neu = '\\n'.join(df_2015_02_neu_sample['text'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473bbfd3",
   "metadata": {},
   "source": [
    "### Prompts and loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84faf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2 = prompt_raw.replace('TWEETS', text_gpt_2015_02_neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d763f6d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4o-mini\",  \n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt_2}\n",
    "    ],\n",
    "    max_tokens=400,  # Maximum number of tokens in the response\n",
    "    temperature=0.7  # Controls the randomness of the output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8ad460",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9e27ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary = []\n",
    "#dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aeb4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.append(\"2015_02_neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd6061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.append(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8327de13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_2015_neu = pd.DataFrame(list(zip(dataset, summary)),\n",
    "                            columns = ['dataset', 'summary'])\n",
    "df_2015_neu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a464a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015_neu.tail(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2553c395",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9543d87",
   "metadata": {},
   "source": [
    "## March"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a1b784",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get monthly data\n",
    "df_2015_03_neu = pd.read_csv('../data/local/df_neu_2015-03.csv').reset_index()\n",
    "df_2015_03_neu.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3ac3e5",
   "metadata": {},
   "source": [
    "### Representative sample based on week and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e554652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the size of each group (year_week, LocationName)\n",
    "group_sizes = df_2015_03_neu.groupby(['year_week', 'LocationName']).size().reset_index(name='group_size')\n",
    "\n",
    "# Step 2: Calculate the proportion of each group in the dataset\n",
    "total_rows = len(df_2015_03_neu)\n",
    "group_sizes['proportion'] = group_sizes['group_size'] / total_rows\n",
    "group_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3c8a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the target sample size\n",
    "target_sample_size = 2450\n",
    "\n",
    "# Step 4: Calculate the sample size for each group (based on its proportion)\n",
    "group_sizes['sample_size'] = np.floor(group_sizes['proportion'] * target_sample_size).astype(int)\n",
    "group_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3199567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Merge this sample size information back to the original DataFrame\n",
    "df_2015_03_neu_sample_size = pd.merge(df_2015_03_neu, group_sizes[['year_week', 'LocationName', 'sample_size']], \n",
    "                               on=['year_week', 'LocationName'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bda885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Perform the stratified sampling\n",
    "df_2015_03_neu_sample = df_2015_03_neu_sample_size.groupby(['year_week', 'LocationName']).apply(\n",
    "    lambda group: group.sample(n=group['sample_size'].iloc[0], random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Step 7: Check the result\n",
    "print(f\"Sampled {len(df_2015_03_neu_sample)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fa81a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gpt_2015_03_neu = '\\n'.join(df_2015_03_neu_sample['text'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8667813b",
   "metadata": {},
   "source": [
    "### Prompts and loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacb83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_3 = prompt_raw.replace('TWEETS', text_gpt_2015_03_neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d6fe7e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4o-mini\",  \n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt_3}\n",
    "    ],\n",
    "    max_tokens=400,  # Maximum number of tokens in the response\n",
    "    temperature=0.7  # Controls the randomness of the output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df41b84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef274df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary = []\n",
    "#dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457a283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.append(\"2015_03_neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe793b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.append(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f918a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_2015_neu = pd.DataFrame(list(zip(dataset, summary)),\n",
    "                            columns = ['dataset', 'summary'])\n",
    "df_2015_neu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33094c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015_neu.tail(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786d137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831ae281",
   "metadata": {},
   "source": [
    "## April"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f75754",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get monthly data\n",
    "df_2015_04_neu = pd.read_csv('../data/local/df_neu_2015-04.csv').reset_index()\n",
    "df_2015_04_neu.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e58f5c",
   "metadata": {},
   "source": [
    "### Representative sample based on week and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220978bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the size of each group (year_week, LocationName)\n",
    "group_sizes = df_2015_04_neu.groupby(['year_week', 'LocationName']).size().reset_index(name='group_size')\n",
    "\n",
    "# Step 2: Calculate the proportion of each group in the dataset\n",
    "total_rows = len(df_2015_04_neu)\n",
    "group_sizes['proportion'] = group_sizes['group_size'] / total_rows\n",
    "group_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d52380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the target sample size\n",
    "target_sample_size = 2450\n",
    "\n",
    "# Step 4: Calculate the sample size for each group (based on its proportion)\n",
    "group_sizes['sample_size'] = np.floor(group_sizes['proportion'] * target_sample_size).astype(int)\n",
    "group_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3186670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Merge this sample size information back to the original DataFrame\n",
    "df_2015_04_neu_sample_size = pd.merge(df_2015_04_neu, group_sizes[['year_week', 'LocationName', 'sample_size']], \n",
    "                               on=['year_week', 'LocationName'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da623d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Perform the stratified sampling\n",
    "df_2015_04_neu_sample = df_2015_04_neu_sample_size.groupby(['year_week', 'LocationName']).apply(\n",
    "    lambda group: group.sample(n=group['sample_size'].iloc[0], random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Step 7: Check the result\n",
    "print(f\"Sampled {len(df_2015_04_neu_sample)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06886cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gpt_2015_04_neu = '\\n'.join(df_2015_04_neu_sample['text'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cd54a3",
   "metadata": {},
   "source": [
    "### Prompts and loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5908cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_4 = prompt_raw.replace('TWEETS', text_gpt_2015_04_neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1948a31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4o-mini\",  \n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt_4}\n",
    "    ],\n",
    "    max_tokens=400,  # Maximum number of tokens in the response\n",
    "    temperature=0.7  # Controls the randomness of the output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3001d55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9884359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary = []\n",
    "#dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c267cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.append(\"2015_04_neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cc4b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.append(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7efe9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_2015_neu = pd.DataFrame(list(zip(dataset, summary)),\n",
    "                            columns = ['dataset', 'summary'])\n",
    "df_2015_neu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbcb530",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015_neu.tail(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e25bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06842bac",
   "metadata": {},
   "source": [
    "## May"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe75998a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get monthly data\n",
    "df_2015_05_neu = pd.read_csv('../data/local/df_neu_2015-05.csv').reset_index()\n",
    "df_2015_05_neu.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02091c0",
   "metadata": {},
   "source": [
    "### Representative sample based on week and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f961f47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the size of each group (year_week, LocationName)\n",
    "group_sizes = df_2015_05_neu.groupby(['year_week', 'LocationName']).size().reset_index(name='group_size')\n",
    "\n",
    "# Step 2: Calculate the proportion of each group in the dataset\n",
    "total_rows = len(df_2015_05_neu)\n",
    "group_sizes['proportion'] = group_sizes['group_size'] / total_rows\n",
    "group_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84177f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the target sample size\n",
    "target_sample_size = 2450\n",
    "\n",
    "# Step 4: Calculate the sample size for each group (based on its proportion)\n",
    "group_sizes['sample_size'] = np.floor(group_sizes['proportion'] * target_sample_size).astype(int)\n",
    "group_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f4ba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Merge this sample size information back to the original DataFrame\n",
    "df_2015_05_neu_sample_size = pd.merge(df_2015_05_neu, group_sizes[['year_week', 'LocationName', 'sample_size']], \n",
    "                               on=['year_week', 'LocationName'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024fe31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Perform the stratified sampling\n",
    "df_2015_05_neu_sample = df_2015_05_neu_sample_size.groupby(['year_week', 'LocationName']).apply(\n",
    "    lambda group: group.sample(n=group['sample_size'].iloc[0], random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Step 7: Check the result\n",
    "print(f\"Sampled {len(df_2015_05_neu_sample)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d01681",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gpt_2015_05_neu = '\\n'.join(df_2015_05_neu_sample['text'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b66d9fa",
   "metadata": {},
   "source": [
    "### Prompts and loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bf6697",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_5 = prompt_raw.replace('TWEETS', text_gpt_2015_05_neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e0d92",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4o-mini\",  \n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt_5}\n",
    "    ],\n",
    "    max_tokens=400,  # Maximum number of tokens in the response\n",
    "    temperature=0.7  # Controls the randomness of the output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b93f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2d6935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary = []\n",
    "#dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b29f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.append(\"2015_05_neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c1fa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.append(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6afc9cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_2015_neu = pd.DataFrame(list(zip(dataset, summary)),\n",
    "                            columns = ['dataset', 'summary'])\n",
    "df_2015_neu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c55f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015_neu.tail(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf871d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2814c4e",
   "metadata": {},
   "source": [
    "## June"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c18d7f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get monthly data\n",
    "df_2015_06_neu = pd.read_csv('../data/local/df_neu_2015-06.csv').reset_index()\n",
    "df_2015_06_neu.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5ba4b0",
   "metadata": {},
   "source": [
    "### Representative sample based on week and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3131b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the size of each group (year_week, LocationName)\n",
    "group_sizes = df_2015_06_neu.groupby(['year_week', 'LocationName']).size().reset_index(name='group_size')\n",
    "\n",
    "# Step 2: Calculate the proportion of each group in the dataset\n",
    "total_rows = len(df_2015_06_neu)\n",
    "group_sizes['proportion'] = group_sizes['group_size'] / total_rows\n",
    "group_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eb60c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the target sample size\n",
    "target_sample_size = 2450\n",
    "\n",
    "# Step 4: Calculate the sample size for each group (based on its proportion)\n",
    "group_sizes['sample_size'] = np.floor(group_sizes['proportion'] * target_sample_size).astype(int)\n",
    "group_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f737f753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Merge this sample size information back to the original DataFrame\n",
    "df_2015_06_neu_sample_size = pd.merge(df_2015_06_neu, group_sizes[['year_week', 'LocationName', 'sample_size']], \n",
    "                               on=['year_week', 'LocationName'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6be4f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Perform the stratified sampling\n",
    "df_2015_06_neu_sample = df_2015_06_neu_sample_size.groupby(['year_week', 'LocationName']).apply(\n",
    "    lambda group: group.sample(n=group['sample_size'].iloc[0], random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Step 7: Check the result\n",
    "print(f\"Sampled {len(df_2015_06_neu_sample)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e283ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gpt_2015_06_neu = '\\n'.join(df_2015_06_neu_sample['text'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318bee7a",
   "metadata": {},
   "source": [
    "### Prompts and loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be18c816",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_6 = prompt_raw.replace('TWEETS', text_gpt_2015_06_neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96369898",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4o-mini\",  \n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt_6}\n",
    "    ],\n",
    "    max_tokens=400,  # Maximum number of tokens in the response\n",
    "    temperature=0.7  # Controls the randomness of the output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b829d3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c71c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary = []\n",
    "#dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dcf233",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.append(\"2015_06_neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78b7b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.append(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcf0103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_2015_neu = pd.DataFrame(list(zip(dataset, summary)),\n",
    "                            columns = ['dataset', 'summary'])\n",
    "df_2015_neu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a785ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015_neu.tail(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86671a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5c5a9b",
   "metadata": {},
   "source": [
    "## July"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5096b4ba",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get monthly data\n",
    "df_2015_07_neu = pd.read_csv('../data/local/df_neu_2015-07.csv').reset_index()\n",
    "df_2015_07_neu.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd1752b",
   "metadata": {},
   "source": [
    "### Representative sample based on week and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62e79b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the size of each group (year_week, LocationName)\n",
    "group_sizes = df_2015_07_neu.groupby(['year_week', 'LocationName']).size().reset_index(name='group_size')\n",
    "\n",
    "# Step 2: Calculate the proportion of each group in the dataset\n",
    "total_rows = len(df_2015_07_neu)\n",
    "group_sizes['proportion'] = group_sizes['group_size'] / total_rows\n",
    "group_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b60716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the target sample size\n",
    "target_sample_size = 2450\n",
    "\n",
    "# Step 4: Calculate the sample size for each group (based on its proportion)\n",
    "group_sizes['sample_size'] = np.floor(group_sizes['proportion'] * target_sample_size).astype(int)\n",
    "group_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c991d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Merge this sample size information back to the original DataFrame\n",
    "df_2015_07_neu_sample_size = pd.merge(df_2015_07_neu, group_sizes[['year_week', 'LocationName', 'sample_size']], \n",
    "                               on=['year_week', 'LocationName'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deab4678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Perform the stratified sampling\n",
    "df_2015_07_neu_sample = df_2015_07_neu_sample_size.groupby(['year_week', 'LocationName']).apply(\n",
    "    lambda group: group.sample(n=group['sample_size'].iloc[0], random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Step 7: Check the result\n",
    "print(f\"Sampled {len(df_2015_07_neu_sample)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33656dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gpt_2015_07_neu = '\\n'.join(df_2015_07_neu_sample['text'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d7e0ea",
   "metadata": {},
   "source": [
    "### Prompts and loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349334a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_7 = prompt_raw.replace('TWEETS', text_gpt_2015_07_neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff46a08b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4o-mini\",  \n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt_7}\n",
    "    ],\n",
    "    max_tokens=400,  # Maximum number of tokens in the response\n",
    "    temperature=0.7  # Controls the randomness of the output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6723c1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3081509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary = []\n",
    "#dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba0dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.append(\"2015_07_neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadb0bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.append(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80e1e4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_2015_neu = pd.DataFrame(list(zip(dataset, summary)),\n",
    "                            columns = ['dataset', 'summary'])\n",
    "df_2015_neu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de211f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015_neu.tail(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19075d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d083d2a",
   "metadata": {},
   "source": [
    "## August"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed2a943",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get monthly data\n",
    "df_2015_08_neu = pd.read_csv('../data/local/df_neu_2015-08.csv').reset_index()\n",
    "df_2015_08_neu.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c035145",
   "metadata": {},
   "source": [
    "### Representative sample based on week and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf072ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the size of each group (year_week, LocationName)\n",
    "group_sizes = df_2015_08_neu.groupby(['year_week', 'LocationName']).size().reset_index(name='group_size')\n",
    "\n",
    "# Step 2: Calculate the proportion of each group in the dataset\n",
    "total_rows = len(df_2015_08_neu)\n",
    "group_sizes['proportion'] = group_sizes['group_size'] / total_rows\n",
    "group_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bc6232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the target sample size\n",
    "target_sample_size = 2450\n",
    "\n",
    "# Step 4: Calculate the sample size for each group (based on its proportion)\n",
    "group_sizes['sample_size'] = np.floor(group_sizes['proportion'] * target_sample_size).astype(int)\n",
    "group_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f55ef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Merge this sample size information back to the original DataFrame\n",
    "df_2015_08_neu_sample_size = pd.merge(df_2015_08_neu, group_sizes[['year_week', 'LocationName', 'sample_size']], \n",
    "                               on=['year_week', 'LocationName'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa2083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Perform the stratified sampling\n",
    "df_2015_08_neu_sample = df_2015_08_neu_sample_size.groupby(['year_week', 'LocationName']).apply(\n",
    "    lambda group: group.sample(n=group['sample_size'].iloc[0], random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Step 7: Check the result\n",
    "print(f\"Sampled {len(df_2015_08_neu_sample)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb70c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gpt_2015_08_neu = '\\n'.join(df_2015_08_neu_sample['text'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c12a08",
   "metadata": {},
   "source": [
    "### Prompts and loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbedf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_8 = prompt_raw.replace('TWEETS', text_gpt_2015_08_neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6312a680",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4o-mini\",  \n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt_8}\n",
    "    ],\n",
    "    max_tokens=400,  # Maximum number of tokens in the response\n",
    "    temperature=0.7  # Controls the randomness of the output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af4a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2df0aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary = []\n",
    "#dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9714a127",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.append(\"2015_08_neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7118fbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.append(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626416cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_2015_neu = pd.DataFrame(list(zip(dataset, summary)),\n",
    "                            columns = ['dataset', 'summary'])\n",
    "df_2015_neu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9811a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015_neu.tail(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd10153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0c859d",
   "metadata": {},
   "source": [
    "## September"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46970275",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get monthly data\n",
    "df_2015_09_neu = pd.read_csv('../data/local/df_neu_2015-09.csv').reset_index()\n",
    "df_2015_09_neu.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6d95b1",
   "metadata": {},
   "source": [
    "### Representative sample based on week and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c64358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the size of each group (year_week, LocationName)\n",
    "group_sizes = df_2015_09_neu.groupby(['year_week', 'LocationName']).size().reset_index(name='group_size')\n",
    "\n",
    "# Step 2: Calculate the proportion of each group in the dataset\n",
    "total_rows = len(df_2015_09_neu)\n",
    "group_sizes['proportion'] = group_sizes['group_size'] / total_rows\n",
    "group_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f70bf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the target sample size\n",
    "target_sample_size = 2450\n",
    "\n",
    "# Step 4: Calculate the sample size for each group (based on its proportion)\n",
    "group_sizes['sample_size'] = np.floor(group_sizes['proportion'] * target_sample_size).astype(int)\n",
    "group_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbb0b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Merge this sample size information back to the original DataFrame\n",
    "df_2015_09_neu_sample_size = pd.merge(df_2015_09_neu, group_sizes[['year_week', 'LocationName', 'sample_size']], \n",
    "                               on=['year_week', 'LocationName'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62cb3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Perform the stratified sampling\n",
    "df_2015_09_neu_sample = df_2015_09_neu_sample_size.groupby(['year_week', 'LocationName']).apply(\n",
    "    lambda group: group.sample(n=group['sample_size'].iloc[0], random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Step 7: Check the result\n",
    "print(f\"Sampled {len(df_2015_09_neu_sample)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94fe9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gpt_2015_09_neu = '\\n'.join(df_2015_09_neu_sample['text'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7904a7f",
   "metadata": {},
   "source": [
    "### Prompts and loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bbca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_9 = prompt_raw.replace('TWEETS', text_gpt_2015_09_neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ae259f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4o-mini\",  \n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt_9}\n",
    "    ],\n",
    "    max_tokens=400,  # Maximum number of tokens in the response\n",
    "    temperature=0.7  # Controls the randomness of the output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8653eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be7b347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary = []\n",
    "#dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550a921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.append(\"2015_09_neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83240506",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.append(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c75735b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_2015_neu = pd.DataFrame(list(zip(dataset, summary)),\n",
    "                            columns = ['dataset', 'summary'])\n",
    "df_2015_neu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa955f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015_neu.tail(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c204870",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f969b1",
   "metadata": {},
   "source": [
    "## October"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cedc2b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get monthly data\n",
    "df_2015_10_neu = pd.read_csv('../data/local/df_neu_2015-10.csv').reset_index()\n",
    "df_2015_10_neu.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616f674a",
   "metadata": {},
   "source": [
    "### Representative sample based on week and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb193cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the size of each group (year_week, LocationName)\n",
    "group_sizes = df_2015_10_neu.groupby(['year_week', 'LocationName']).size().reset_index(name='group_size')\n",
    "\n",
    "# Step 2: Calculate the proportion of each group in the dataset\n",
    "total_rows = len(df_2015_10_neu)\n",
    "group_sizes['proportion'] = group_sizes['group_size'] / total_rows\n",
    "group_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610efcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the target sample size\n",
    "target_sample_size = 2450\n",
    "\n",
    "# Step 4: Calculate the sample size for each group (based on its proportion)\n",
    "group_sizes['sample_size'] = np.floor(group_sizes['proportion'] * target_sample_size).astype(int)\n",
    "group_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "361d2734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Merge this sample size information back to the original DataFrame\n",
    "df_2015_10_neu_sample_size = pd.merge(df_2015_10_neu, group_sizes[['year_week', 'LocationName', 'sample_size']], \n",
    "                               on=['year_week', 'LocationName'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "cd34d6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 2230 rows.\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Perform the stratified sampling\n",
    "#df_2015_10_neu_sample = df_2015_10_neu_sample_size.groupby(['year_week', 'LocationName']).apply(\n",
    " #   lambda group: group.sample(n=group['sample_size'].iloc[0], random_state=42)\n",
    "#).reset_index(drop=True)\n",
    "df_2015_10_neu_sample = df_2015_10_neu\n",
    "# Step 7: Check the result\n",
    "print(f\"Sampled {len(df_2015_10_neu_sample)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "853aa7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gpt_2015_10_neu = '\\n'.join(df_2015_10_neu_sample['text'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e857dd6",
   "metadata": {},
   "source": [
    "### Prompts and loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "997a28ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_10 = prompt_raw.replace('TWEETS', text_gpt_2015_10_neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0ad6cb21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4o-mini\",  \n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt_10}\n",
    "    ],\n",
    "    max_tokens=400,  # Maximum number of tokens in the response\n",
    "    temperature=0.7  # Controls the randomness of the output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f98d14d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The text primarily discusses various vaccination campaigns and their importance in preventing diseases for both humans and animals. It highlights the rollout of vaccines against diseases like HPV, dengue, and rabies, as well as mentions specific events and campaigns in different regions. There are also references to personal experiences with vaccinations, humor related to vaccination fears, and the role of vaccination in public health initiatives.'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "148185bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary = []\n",
    "#dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "91999070",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.append(\"2015_10_neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ca0c8fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.append(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "75de78c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   dataset  10 non-null     object\n",
      " 1   summary  10 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 288.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_2015_neu = pd.DataFrame(list(zip(dataset, summary)),\n",
    "                            columns = ['dataset', 'summary'])\n",
    "df_2015_neu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "33f398cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_01_neutral</td>\n",
       "      <td>The text discusses various aspects of vaccinat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_02_neutral</td>\n",
       "      <td>The text discusses various aspects of vaccinat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_03_neutral</td>\n",
       "      <td>A vaccination campaign against HPV is starting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_04_neutral</td>\n",
       "      <td>The text discusses various vaccination campaig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_05_neutral</td>\n",
       "      <td>The sentences discuss the ongoing vaccination ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015_06_neutral</td>\n",
       "      <td>The texts discuss the vaccination campaigns ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015_07_neutral</td>\n",
       "      <td>A vaccination campaign against rabies for dogs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015_08_neutral</td>\n",
       "      <td>The text discusses multiple vaccination campai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015_09_neutral</td>\n",
       "      <td>The texts discuss various vaccination campaign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015_10_neutral</td>\n",
       "      <td>The text primarily discusses various vaccinati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dataset                                            summary\n",
       "0  2015_01_neutral  The text discusses various aspects of vaccinat...\n",
       "1  2015_02_neutral  The text discusses various aspects of vaccinat...\n",
       "2  2015_03_neutral  A vaccination campaign against HPV is starting...\n",
       "3  2015_04_neutral  The text discusses various vaccination campaig...\n",
       "4  2015_05_neutral  The sentences discuss the ongoing vaccination ...\n",
       "5  2015_06_neutral  The texts discuss the vaccination campaigns ag...\n",
       "6  2015_07_neutral  A vaccination campaign against rabies for dogs...\n",
       "7  2015_08_neutral  The text discusses multiple vaccination campai...\n",
       "8  2015_09_neutral  The texts discuss various vaccination campaign...\n",
       "9  2015_10_neutral  The text primarily discusses various vaccinati..."
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2015_neu.tail(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c9aa4469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-AUd9L37kzWssNTB1ACPsIHZtBXgT1 at 0x2d5c718f9f0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"message\": {\n",
       "        \"content\": \"The text primarily discusses various vaccination campaigns and their importance in preventing diseases for both humans and animals. It highlights the rollout of vaccines against diseases like HPV, dengue, and rabies, as well as mentions specific events and campaigns in different regions. There are also references to personal experiences with vaccinations, humor related to vaccination fears, and the role of vaccination in public health initiatives.\",\n",
       "        \"refusal\": null,\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1731863695,\n",
       "  \"id\": \"chatcmpl-AUd9L37kzWssNTB1ACPsIHZtBXgT1\",\n",
       "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"system_fingerprint\": \"fp_9b78b61c52\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 74,\n",
       "    \"completion_tokens_details\": {\n",
       "      \"accepted_prediction_tokens\": 0,\n",
       "      \"audio_tokens\": 0,\n",
       "      \"reasoning_tokens\": 0,\n",
       "      \"rejected_prediction_tokens\": 0\n",
       "    },\n",
       "    \"prompt_tokens\": 49434,\n",
       "    \"prompt_tokens_details\": {\n",
       "      \"audio_tokens\": 0,\n",
       "      \"cached_tokens\": 0\n",
       "    },\n",
       "    \"total_tokens\": 49508\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d476f7a3",
   "metadata": {},
   "source": [
    "## November"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "63dc91c7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3179 entries, 0 to 3178\n",
      "Data columns (total 53 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   index                   3179 non-null   int64  \n",
      " 1   LocationCode            3179 non-null   object \n",
      " 2   LocationName            3179 non-null   object \n",
      " 3   StatesCode              3179 non-null   object \n",
      " 4   ...4                    3179 non-null   int64  \n",
      " 5   id                      3179 non-null   float64\n",
      " 6   text                    3179 non-null   object \n",
      " 7   label                   3179 non-null   object \n",
      " 8   in_reply_to_status_id   174 non-null    float64\n",
      " 9   in_reply_to_user_id     216 non-null    float64\n",
      " 10  quoted_user_id          19 non-null     float64\n",
      " 11  quoted_status_id        19 non-null     float64\n",
      " 12  retweeted_user_id       334 non-null    float64\n",
      " 13  retweeted_status_id     334 non-null    float64\n",
      " 14  created_at              3179 non-null   object \n",
      " 15  entities.user_mentions  821 non-null    object \n",
      " 16  user.id                 3179 non-null   int64  \n",
      " 17  user.screen_name        3179 non-null   object \n",
      " 18  user.name               3179 non-null   object \n",
      " 19  user.description        2776 non-null   object \n",
      " 20  user.timezone           0 non-null      float64\n",
      " 21  user.location           3128 non-null   object \n",
      " 22  user.num_followers      3179 non-null   int64  \n",
      " 23  user.num_following      3179 non-null   int64  \n",
      " 24  user.created_at         3179 non-null   object \n",
      " 25  user.statuses_count     3179 non-null   int64  \n",
      " 26  user.is_verified        3179 non-null   bool   \n",
      " 27  lang                    3179 non-null   object \n",
      " 28  token_count             3179 non-null   int64  \n",
      " 29  is_retweet              3179 non-null   bool   \n",
      " 30  has_quote               3179 non-null   bool   \n",
      " 31  is_reply                3179 non-null   bool   \n",
      " 32  contains_keywords       3179 non-null   bool   \n",
      " 33  longitude               3179 non-null   float64\n",
      " 34  latitude                3179 non-null   float64\n",
      " 35  country_code            3179 non-null   object \n",
      " 36  geoname_id              2954 non-null   float64\n",
      " 37  location_type           3179 non-null   object \n",
      " 38  geo_type                3179 non-null   int64  \n",
      " 39  region                  3179 non-null   object \n",
      " 40  subregion               3179 non-null   object \n",
      " 41  num_quotes              3179 non-null   int64  \n",
      " 42  num_replies             3179 non-null   int64  \n",
      " 43  num_retweets            3179 non-null   int64  \n",
      " 44  sent_gpt                3179 non-null   object \n",
      " 45  gpt_sent_presence       3179 non-null   int64  \n",
      " 46  cleaned_text_lem        3179 non-null   object \n",
      " 47  cleaned_text            3179 non-null   object \n",
      " 48  month                   3179 non-null   int64  \n",
      " 49  year                    3179 non-null   int64  \n",
      " 50  week                    3179 non-null   int64  \n",
      " 51  year_month              3179 non-null   object \n",
      " 52  year_week               3179 non-null   object \n",
      "dtypes: bool(5), float64(11), int64(15), object(22)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Get monthly data\n",
    "df_2015_11_neu = pd.read_csv('../data/local/df_neu_2015-11.csv').reset_index()\n",
    "df_2015_11_neu.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44ca951",
   "metadata": {},
   "source": [
    "### Representative sample based on week and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "58f0a8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_week</th>\n",
       "      <th>LocationName</th>\n",
       "      <th>group_size</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-w44</td>\n",
       "      <td>Alagoas</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-w44</td>\n",
       "      <td>Amapa</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-w44</td>\n",
       "      <td>Amazonas</td>\n",
       "      <td>9</td>\n",
       "      <td>0.002831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-w44</td>\n",
       "      <td>Bahia</td>\n",
       "      <td>56</td>\n",
       "      <td>0.017616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-w44</td>\n",
       "      <td>Ceara</td>\n",
       "      <td>16</td>\n",
       "      <td>0.005033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2015-w48</td>\n",
       "      <td>Roraima</td>\n",
       "      <td>7</td>\n",
       "      <td>0.002202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2015-w48</td>\n",
       "      <td>Santa Catarina</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2015-w48</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>39</td>\n",
       "      <td>0.012268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2015-w48</td>\n",
       "      <td>Sergipe</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2015-w48</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    year_week    LocationName  group_size  proportion\n",
       "0    2015-w44         Alagoas           5    0.001573\n",
       "1    2015-w44           Amapa           2    0.000629\n",
       "2    2015-w44        Amazonas           9    0.002831\n",
       "3    2015-w44           Bahia          56    0.017616\n",
       "4    2015-w44           Ceara          16    0.005033\n",
       "..        ...             ...         ...         ...\n",
       "110  2015-w48         Roraima           7    0.002202\n",
       "111  2015-w48  Santa Catarina           4    0.001258\n",
       "112  2015-w48       Sao Paulo          39    0.012268\n",
       "113  2015-w48         Sergipe           1    0.000315\n",
       "114  2015-w48       Tocantins           3    0.000944\n",
       "\n",
       "[115 rows x 4 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Calculate the size of each group (year_week, LocationName)\n",
    "group_sizes = df_2015_11_neu.groupby(['year_week', 'LocationName']).size().reset_index(name='group_size')\n",
    "\n",
    "# Step 2: Calculate the proportion of each group in the dataset\n",
    "total_rows = len(df_2015_11_neu)\n",
    "group_sizes['proportion'] = group_sizes['group_size'] / total_rows\n",
    "group_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "52c7e839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_week</th>\n",
       "      <th>LocationName</th>\n",
       "      <th>group_size</th>\n",
       "      <th>proportion</th>\n",
       "      <th>sample_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-w44</td>\n",
       "      <td>Alagoas</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-w44</td>\n",
       "      <td>Amapa</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-w44</td>\n",
       "      <td>Amazonas</td>\n",
       "      <td>9</td>\n",
       "      <td>0.002831</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-w44</td>\n",
       "      <td>Bahia</td>\n",
       "      <td>56</td>\n",
       "      <td>0.017616</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-w44</td>\n",
       "      <td>Ceara</td>\n",
       "      <td>16</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2015-w48</td>\n",
       "      <td>Roraima</td>\n",
       "      <td>7</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2015-w48</td>\n",
       "      <td>Santa Catarina</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2015-w48</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>39</td>\n",
       "      <td>0.012268</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2015-w48</td>\n",
       "      <td>Sergipe</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2015-w48</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    year_week    LocationName  group_size  proportion  sample_size\n",
       "0    2015-w44         Alagoas           5    0.001573            3\n",
       "1    2015-w44           Amapa           2    0.000629            1\n",
       "2    2015-w44        Amazonas           9    0.002831            6\n",
       "3    2015-w44           Bahia          56    0.017616           43\n",
       "4    2015-w44           Ceara          16    0.005033           12\n",
       "..        ...             ...         ...         ...          ...\n",
       "110  2015-w48         Roraima           7    0.002202            5\n",
       "111  2015-w48  Santa Catarina           4    0.001258            3\n",
       "112  2015-w48       Sao Paulo          39    0.012268           30\n",
       "113  2015-w48         Sergipe           1    0.000315            0\n",
       "114  2015-w48       Tocantins           3    0.000944            2\n",
       "\n",
       "[115 rows x 5 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Define the target sample size\n",
    "target_sample_size = 2450\n",
    "\n",
    "# Step 4: Calculate the sample size for each group (based on its proportion)\n",
    "group_sizes['sample_size'] = np.floor(group_sizes['proportion'] * target_sample_size).astype(int)\n",
    "group_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "47bfacf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Merge this sample size information back to the original DataFrame\n",
    "df_2015_11_neu_sample_size = pd.merge(df_2015_11_neu, group_sizes[['year_week', 'LocationName', 'sample_size']], \n",
    "                               on=['year_week', 'LocationName'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "3127c68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 2387 rows.\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Perform the stratified sampling\n",
    "df_2015_11_neu_sample = df_2015_11_neu_sample_size.groupby(['year_week', 'LocationName']).apply(\n",
    "    lambda group: group.sample(n=group['sample_size'].iloc[0], random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Step 7: Check the result\n",
    "print(f\"Sampled {len(df_2015_11_neu_sample)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a5fc3ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gpt_2015_11_neu = '\\n'.join(df_2015_11_neu_sample['text'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df94c41",
   "metadata": {},
   "source": [
    "### Prompts and loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b2c43f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_11 = prompt_raw.replace('TWEETS', text_gpt_2015_11_neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "87bbf147",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4o-mini\",  \n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt_11}\n",
    "    ],\n",
    "    max_tokens=400,  # Maximum number of tokens in the response\n",
    "    temperature=0.7  # Controls the randomness of the output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "99d409e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The text discusses various campaigns and phases of vaccination against foot-and-mouth disease affecting livestock in Brazil, emphasizing the importance of vaccinating the herd to maintain disease-free status. It highlights deadlines for vaccination, awareness campaigns for rural producers, and the impact on meat exportation.'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c1cb7d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary = []\n",
    "#dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0b5f7bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.append(\"2015_11_neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "25b7e5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.append(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "10f2f273",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11 entries, 0 to 10\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   dataset  11 non-null     object\n",
      " 1   summary  11 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 304.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_2015_neu = pd.DataFrame(list(zip(dataset, summary)),\n",
    "                            columns = ['dataset', 'summary'])\n",
    "df_2015_neu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "89ced529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_01_neutral</td>\n",
       "      <td>The text discusses various aspects of vaccinat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_02_neutral</td>\n",
       "      <td>The text discusses various aspects of vaccinat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_03_neutral</td>\n",
       "      <td>A vaccination campaign against HPV is starting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_04_neutral</td>\n",
       "      <td>The text discusses various vaccination campaig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_05_neutral</td>\n",
       "      <td>The sentences discuss the ongoing vaccination ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015_06_neutral</td>\n",
       "      <td>The texts discuss the vaccination campaigns ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015_07_neutral</td>\n",
       "      <td>A vaccination campaign against rabies for dogs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015_08_neutral</td>\n",
       "      <td>The text discusses multiple vaccination campai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015_09_neutral</td>\n",
       "      <td>The texts discuss various vaccination campaign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015_10_neutral</td>\n",
       "      <td>The text primarily discusses various vaccinati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2015_11_neutral</td>\n",
       "      <td>The text discusses various campaigns and phase...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dataset                                            summary\n",
       "0   2015_01_neutral  The text discusses various aspects of vaccinat...\n",
       "1   2015_02_neutral  The text discusses various aspects of vaccinat...\n",
       "2   2015_03_neutral  A vaccination campaign against HPV is starting...\n",
       "3   2015_04_neutral  The text discusses various vaccination campaig...\n",
       "4   2015_05_neutral  The sentences discuss the ongoing vaccination ...\n",
       "5   2015_06_neutral  The texts discuss the vaccination campaigns ag...\n",
       "6   2015_07_neutral  A vaccination campaign against rabies for dogs...\n",
       "7   2015_08_neutral  The text discusses multiple vaccination campai...\n",
       "8   2015_09_neutral  The texts discuss various vaccination campaign...\n",
       "9   2015_10_neutral  The text primarily discusses various vaccinati...\n",
       "10  2015_11_neutral  The text discusses various campaigns and phase..."
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2015_neu.tail(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "952c4bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-AUd9SVlelM9qGOtdmczyrZZ9CamQ4 at 0x2d5ca960a40> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"message\": {\n",
       "        \"content\": \"The text discusses various campaigns and phases of vaccination against foot-and-mouth disease affecting livestock in Brazil, emphasizing the importance of vaccinating the herd to maintain disease-free status. It highlights deadlines for vaccination, awareness campaigns for rural producers, and the impact on meat exportation.\",\n",
       "        \"refusal\": null,\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1731863702,\n",
       "  \"id\": \"chatcmpl-AUd9SVlelM9qGOtdmczyrZZ9CamQ4\",\n",
       "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"system_fingerprint\": \"fp_0ba0d124f1\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 53,\n",
       "    \"completion_tokens_details\": {\n",
       "      \"accepted_prediction_tokens\": 0,\n",
       "      \"audio_tokens\": 0,\n",
       "      \"reasoning_tokens\": 0,\n",
       "      \"rejected_prediction_tokens\": 0\n",
       "    },\n",
       "    \"prompt_tokens\": 58180,\n",
       "    \"prompt_tokens_details\": {\n",
       "      \"audio_tokens\": 0,\n",
       "      \"cached_tokens\": 0\n",
       "    },\n",
       "    \"total_tokens\": 58233\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46613a39",
   "metadata": {},
   "source": [
    "## December"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "3f6bde3b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4472 entries, 0 to 4471\n",
      "Data columns (total 53 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   index                   4472 non-null   int64  \n",
      " 1   LocationCode            4472 non-null   object \n",
      " 2   LocationName            4472 non-null   object \n",
      " 3   StatesCode              4472 non-null   object \n",
      " 4   ...4                    4472 non-null   int64  \n",
      " 5   id                      4472 non-null   float64\n",
      " 6   text                    4472 non-null   object \n",
      " 7   label                   4472 non-null   object \n",
      " 8   in_reply_to_status_id   214 non-null    float64\n",
      " 9   in_reply_to_user_id     392 non-null    float64\n",
      " 10  quoted_user_id          33 non-null     float64\n",
      " 11  quoted_status_id        33 non-null     float64\n",
      " 12  retweeted_user_id       1335 non-null   float64\n",
      " 13  retweeted_status_id     1335 non-null   float64\n",
      " 14  created_at              4472 non-null   object \n",
      " 15  entities.user_mentions  2017 non-null   object \n",
      " 16  user.id                 4472 non-null   int64  \n",
      " 17  user.screen_name        4472 non-null   object \n",
      " 18  user.name               4472 non-null   object \n",
      " 19  user.description        3886 non-null   object \n",
      " 20  user.timezone           0 non-null      float64\n",
      " 21  user.location           4425 non-null   object \n",
      " 22  user.num_followers      4472 non-null   int64  \n",
      " 23  user.num_following      4472 non-null   int64  \n",
      " 24  user.created_at         4472 non-null   object \n",
      " 25  user.statuses_count     4472 non-null   int64  \n",
      " 26  user.is_verified        4472 non-null   bool   \n",
      " 27  lang                    4472 non-null   object \n",
      " 28  token_count             4472 non-null   int64  \n",
      " 29  is_retweet              4472 non-null   bool   \n",
      " 30  has_quote               4472 non-null   bool   \n",
      " 31  is_reply                4472 non-null   bool   \n",
      " 32  contains_keywords       4472 non-null   bool   \n",
      " 33  longitude               4472 non-null   float64\n",
      " 34  latitude                4472 non-null   float64\n",
      " 35  country_code            4472 non-null   object \n",
      " 36  geoname_id              4237 non-null   float64\n",
      " 37  location_type           4472 non-null   object \n",
      " 38  geo_type                4472 non-null   int64  \n",
      " 39  region                  4472 non-null   object \n",
      " 40  subregion               4472 non-null   object \n",
      " 41  num_quotes              4472 non-null   int64  \n",
      " 42  num_replies             4472 non-null   int64  \n",
      " 43  num_retweets            4472 non-null   int64  \n",
      " 44  sent_gpt                4472 non-null   object \n",
      " 45  gpt_sent_presence       4472 non-null   int64  \n",
      " 46  cleaned_text_lem        4472 non-null   object \n",
      " 47  cleaned_text            4472 non-null   object \n",
      " 48  month                   4472 non-null   int64  \n",
      " 49  year                    4472 non-null   int64  \n",
      " 50  week                    4472 non-null   int64  \n",
      " 51  year_month              4472 non-null   object \n",
      " 52  year_week               4472 non-null   object \n",
      "dtypes: bool(5), float64(11), int64(15), object(22)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Get monthly data\n",
    "df_2015_12_neu = pd.read_csv('../data/local/df_neu_2015-12.csv').reset_index()\n",
    "df_2015_12_neu.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4658d918",
   "metadata": {},
   "source": [
    "### Representative sample based on week and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "fcdbb1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_week</th>\n",
       "      <th>LocationName</th>\n",
       "      <th>group_size</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-w48</td>\n",
       "      <td>Alagoas</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-w48</td>\n",
       "      <td>Amazonas</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-w48</td>\n",
       "      <td>Bahia</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-w48</td>\n",
       "      <td>Ceara</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-w48</td>\n",
       "      <td>Espirito Santo</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2015-w53</td>\n",
       "      <td>Parana</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2015-w53</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2015-w53</td>\n",
       "      <td>Rio Grande Do Sul</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2015-w53</td>\n",
       "      <td>Santa Catarina</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2015-w53</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    year_week       LocationName  group_size  proportion\n",
       "0    2015-w48            Alagoas           2    0.000447\n",
       "1    2015-w48           Amazonas           2    0.000447\n",
       "2    2015-w48              Bahia           5    0.001118\n",
       "3    2015-w48              Ceara           2    0.000447\n",
       "4    2015-w48     Espirito Santo           2    0.000447\n",
       "..        ...                ...         ...         ...\n",
       "122  2015-w53             Parana           1    0.000224\n",
       "123  2015-w53         Pernambuco           1    0.000224\n",
       "124  2015-w53  Rio Grande Do Sul           2    0.000447\n",
       "125  2015-w53     Santa Catarina           1    0.000224\n",
       "126  2015-w53          Sao Paulo           3    0.000671\n",
       "\n",
       "[127 rows x 4 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Calculate the size of each group (year_week, LocationName)\n",
    "group_sizes = df_2015_12_neu.groupby(['year_week', 'LocationName']).size().reset_index(name='group_size')\n",
    "\n",
    "# Step 2: Calculate the proportion of each group in the dataset\n",
    "total_rows = len(df_2015_12_neu)\n",
    "group_sizes['proportion'] = group_sizes['group_size'] / total_rows\n",
    "group_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "bbf24049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_week</th>\n",
       "      <th>LocationName</th>\n",
       "      <th>group_size</th>\n",
       "      <th>proportion</th>\n",
       "      <th>sample_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-w48</td>\n",
       "      <td>Alagoas</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-w48</td>\n",
       "      <td>Amazonas</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-w48</td>\n",
       "      <td>Bahia</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-w48</td>\n",
       "      <td>Ceara</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-w48</td>\n",
       "      <td>Espirito Santo</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2015-w53</td>\n",
       "      <td>Parana</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2015-w53</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2015-w53</td>\n",
       "      <td>Rio Grande Do Sul</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2015-w53</td>\n",
       "      <td>Santa Catarina</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2015-w53</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    year_week       LocationName  group_size  proportion  sample_size\n",
       "0    2015-w48            Alagoas           2    0.000447            1\n",
       "1    2015-w48           Amazonas           2    0.000447            1\n",
       "2    2015-w48              Bahia           5    0.001118            2\n",
       "3    2015-w48              Ceara           2    0.000447            1\n",
       "4    2015-w48     Espirito Santo           2    0.000447            1\n",
       "..        ...                ...         ...         ...          ...\n",
       "122  2015-w53             Parana           1    0.000224            0\n",
       "123  2015-w53         Pernambuco           1    0.000224            0\n",
       "124  2015-w53  Rio Grande Do Sul           2    0.000447            1\n",
       "125  2015-w53     Santa Catarina           1    0.000224            0\n",
       "126  2015-w53          Sao Paulo           3    0.000671            1\n",
       "\n",
       "[127 rows x 5 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Define the target sample size\n",
    "target_sample_size = 2450\n",
    "\n",
    "# Step 4: Calculate the sample size for each group (based on its proportion)\n",
    "group_sizes['sample_size'] = np.floor(group_sizes['proportion'] * target_sample_size).astype(int)\n",
    "group_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c207c408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Merge this sample size information back to the original DataFrame\n",
    "df_2015_12_neu_sample_size = pd.merge(df_2015_12_neu, group_sizes[['year_week', 'LocationName', 'sample_size']], \n",
    "                               on=['year_week', 'LocationName'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "66d74acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 4472 rows.\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Perform the stratified sampling\n",
    "#df_2015_12_neu_sample = df_2015_12_neu_sample_size.groupby(['year_week', 'LocationName']).apply(\n",
    " #   lambda group: group.sample(n=group['sample_size'].iloc[0], random_state=42)\n",
    "#).reset_index(drop=True)\n",
    "df_2015_12_neu_sample = df_2015_12_neu\n",
    "# Step 7: Check the result\n",
    "print(f\"Sampled {len(df_2015_12_neu_sample)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b23befcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gpt_2015_12_neu = '\\n'.join(df_2015_12_neu_sample['text'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3650c4b",
   "metadata": {},
   "source": [
    "### Prompts and loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "791b4fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_12 = prompt_raw.replace('TWEETS', text_gpt_2015_12_neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "def2b9de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4o-mini\",  \n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt_12}\n",
    "    ],\n",
    "    max_tokens=400,  # Maximum number of tokens in the response\n",
    "    temperature=0.7  # Controls the randomness of the output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "eb10f5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The text discusses various aspects of vaccination, particularly focusing on the approval and details of the first dengue vaccine in Brazil by Anvisa. It addresses the target demographics for the vaccine, including children up to 14 years and elderly over 60, while noting concerns about the spread of misinformation relating to other vaccines, such as those for rubella and Zika.'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "82e7aa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary = []\n",
    "#dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2a9d076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.append(\"2015_12_neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8a057dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.append(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3bb6bfbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12 entries, 0 to 11\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   dataset  12 non-null     object\n",
      " 1   summary  12 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 320.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_2015_neu = pd.DataFrame(list(zip(dataset, summary)),\n",
    "                            columns = ['dataset', 'summary'])\n",
    "df_2015_neu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "893bd100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_01_neutral</td>\n",
       "      <td>The text discusses various aspects of vaccinat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_02_neutral</td>\n",
       "      <td>The text discusses various aspects of vaccinat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_03_neutral</td>\n",
       "      <td>A vaccination campaign against HPV is starting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_04_neutral</td>\n",
       "      <td>The text discusses various vaccination campaig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_05_neutral</td>\n",
       "      <td>The sentences discuss the ongoing vaccination ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015_06_neutral</td>\n",
       "      <td>The texts discuss the vaccination campaigns ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015_07_neutral</td>\n",
       "      <td>A vaccination campaign against rabies for dogs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015_08_neutral</td>\n",
       "      <td>The text discusses multiple vaccination campai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015_09_neutral</td>\n",
       "      <td>The texts discuss various vaccination campaign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015_10_neutral</td>\n",
       "      <td>The text primarily discusses various vaccinati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2015_11_neutral</td>\n",
       "      <td>The text discusses various campaigns and phase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2015_12_neutral</td>\n",
       "      <td>The text discusses various aspects of vaccinat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dataset                                            summary\n",
       "0   2015_01_neutral  The text discusses various aspects of vaccinat...\n",
       "1   2015_02_neutral  The text discusses various aspects of vaccinat...\n",
       "2   2015_03_neutral  A vaccination campaign against HPV is starting...\n",
       "3   2015_04_neutral  The text discusses various vaccination campaig...\n",
       "4   2015_05_neutral  The sentences discuss the ongoing vaccination ...\n",
       "5   2015_06_neutral  The texts discuss the vaccination campaigns ag...\n",
       "6   2015_07_neutral  A vaccination campaign against rabies for dogs...\n",
       "7   2015_08_neutral  The text discusses multiple vaccination campai...\n",
       "8   2015_09_neutral  The texts discuss various vaccination campaign...\n",
       "9   2015_10_neutral  The text primarily discusses various vaccinati...\n",
       "10  2015_11_neutral  The text discusses various campaigns and phase...\n",
       "11  2015_12_neutral  The text discusses various aspects of vaccinat..."
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2015_neu.tail(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "20bf36e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-AUd9b0bAmun5P4Zsu6I1xw5I7JDkx at 0x2d5cac5bdb0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"message\": {\n",
       "        \"content\": \"The text discusses various aspects of vaccination, particularly focusing on the approval and details of the first dengue vaccine in Brazil by Anvisa. It addresses the target demographics for the vaccine, including children up to 14 years and elderly over 60, while noting concerns about the spread of misinformation relating to other vaccines, such as those for rubella and Zika.\",\n",
       "        \"refusal\": null,\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1731863711,\n",
       "  \"id\": \"chatcmpl-AUd9b0bAmun5P4Zsu6I1xw5I7JDkx\",\n",
       "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"system_fingerprint\": \"fp_0ba0d124f1\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 71,\n",
       "    \"completion_tokens_details\": {\n",
       "      \"accepted_prediction_tokens\": 0,\n",
       "      \"audio_tokens\": 0,\n",
       "      \"reasoning_tokens\": 0,\n",
       "      \"rejected_prediction_tokens\": 0\n",
       "    },\n",
       "    \"prompt_tokens\": 103778,\n",
       "    \"prompt_tokens_details\": {\n",
       "      \"audio_tokens\": 0,\n",
       "      \"cached_tokens\": 0\n",
       "    },\n",
       "    \"total_tokens\": 103849\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2eea35",
   "metadata": {},
   "source": [
    "## All 2015 neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "0afccf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2015_neu['dataset'] = df_2015_neu['dataset'].str.replace('neuitive','neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "76b26dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015_neu.to_csv('../data/summary_2015_neutral_tweets.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
